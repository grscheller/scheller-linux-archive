The purpose of these notes is to document Bash shell scripting
techniques and give some best practices.  Bash is the official
shell of the GNU Operating System.  The topics discussed are in
no particular order.

These notes are not about how to write lowest common denominator,
maximally portable, "POSIX Compliant/Standard Shell" scripts.
POSIX/Standard Shell is a standard that various UNIX shells,
to a greater or lesser extent, try adhering to.  It should NOT
be confused with the original AT&T Bourne Shell.  POSIX/Standard
Shell is acually based on a subset of the Korn Shell (Ksh) with
interactive ideas from C Shell.

The original Bourne Shell was flawed.  There are features of the
Bourne Shell that are in Bash for backward compatibility.  When
Bash scripting, these features should be avoided as indicated
later in the notes.  When POSIX shell scripting, Bash specific
features should be avoided.

C Shell was revolutionary in its day.  It provides for enhanced
interactive user operability.  Its syntax was modeled after the
C programming language which made it easier for C programmers
to learn.  Unfortunately, it has an inconsistent grammer and its
syntax is rather adhoc across the language.  C Shell is still
sometimes used by (non-computer science) scientists, but
otherwise is dead.

Korn Shell was AT&T's UNIX System V replacement for the Bourne
Shell.  Unfornuately it came out after AT&T made System V
completely proprietary software.  It became very popular in
proprietary UNIXs.

To get the most out of these notes, one needs to be already
functional with Bash.  For a good introductory tutorial,
I suggest "The Linux Command Line" by William Shotts.

01. Globbing:

    Bash will "wildcard match" filenames in the directory
    structure.  This is not to be confused with regular
    expression pattern matching, which is used by commands
    like grep and sed or programming languages like
    Python and Perl.

         * match 0 or more characters
         ? match any character
        [] match any one character between the brackets

02. Extended globbing:

    I usually turn on extended shell pattern matching.

      $ shopt -s extglob

    When turned on, to
    you can additionally use,
        ?() zero or one occurances of pattern
        *() zero or more occurances of pattern
        +() one or more occurances of pattern
        @() one occurance of pattern
        !() anything except the pattern

    case $1 in
        a*           ) foo;;   # match anything starting with a
        b?           ) bar;;   # match 2 characters first being b
        c[de]        ) baz;;   # match cd or ce
        me?(e)t      ) qux;;   # match met or meet
        @(a|e|i|o|u) ) quux;;  # match one vowel
    esac

    Note: Names like foo, bar, baz, and values like 42 are
          examples of what are called "metasyntactic variables."
          They are just meaningless place holders when illustrating
          syntax.  In the above they can represent Linux commands
          or shell functions.  Can also be multiple statements
          separated by newlines or semicolens.

    Note: Case statements end with a "esac", case spelled
          backwards.  If statements end similarly with an "fi".
          This comes from the original Bourne shell where it
          was borrowed from Algol.

03. In Bash version 4 and later, case in addition to ;; has
    ;& and ;;&

        ;&   Fall through without testing next case,
             like in C without break.
        ;;&  Means don't terminate, continue testing.

           case $greating in
               hello*)
                 echo "begins with hello"
                 ;&
               @(h|H)ello*)
                 echo "a friendly greating"
                 echo "this is good"
                 ;;&
               *\!)
                 echo "ends in an exclaimation"
                 ;;
               *.)
                 echo "ends in a period"
                 ;;
            esac

05. Redirection tricks:

    Read from commands or pipes as if they were files.
      $ cat <(echo -e "Hello,\nEveryone" | sed 's/^E.*/there/') <(echo 'World!')
      Hello,
      there
      World!

         Implemented via /dev/fd
           $ echo <(echo hi)
           /dev/fd/63

    Read or write to commands or pipes as if they are files:
      $ cp <(echo -n 'Hello World')  >(cat <(echo -n 'So, ') - <(echo '.'))
      So, Hello World.

    To redirect the output of a command  to a file
      $ cmd > /path/to/file
    This is shorthand for
      $ cmd 1> /path/to/file
    To append instead of overwriting
      $ cmd >> /peth/to/file

    To throw away output
      $ cmd > /dev/null
    To throw away error messages
      $ cmd 2> /dev/null
    Throw away both
      $ cmd > /dev/null 2>&1
      $ cmd &> /dev/null          # Added in Bash 4

    This throws cmd output away and sends error
    output to stdout (common mistake for above - but
    useful if this is what you want to do)
      cmd 2>&1 > /dev/null

    Redirect stderr and stdout to stdin of piped command
      cmd1 |& cmd2

    Send only stderr down a pile:
      cmd1 2>&1 >/dev/null | cmd2
    Swap stderr and stdout:
      cmd1 3>&2 2>&1 >&3 | cmd2

    You can even redirect stdin
      $ echo foobar > junk; cat - 0<junk
      foobar

    Users should use file descriptors < 10 in scripts to avoid
    clashing with ones used by the shell.  Bash starts with
    file descriptor 63 and works its way down.  File descriptors
    0, 1, 2 are predefined:

      stdin  = /dev/fd/0
      stdout = /dev/fd/1
      stderr = /dev/fd/2

    Can also append with stderr
      cmd 2>> file_with_error_messages
    Can append both
      cmd &>> file
    which is the same as
      cmd >> file 2>&1

    Less commonly known is that you can close file descriptures,
    for example, this closes stderr:

      $ cmd 2>&-

    This is NOT the same as

      $ cmd 2>/dev/null

    A lot of times the former and latter seem to accomplish
    the same thing, they gag error messages.  In the latter,
    we are depending that cmd is smart enough to know what
    to do in case it encounters closed file descriptor
    (as in C language file descriptor).  This can be used
    for efficiency, but depends on knowledge of the internal
    workings of commands.  Sometimes cmd complains:

      $ printf 'Hello World\nGood bye for now\n' | tee junk1
      Hello World
      Good bye for now
      $ printf 'Hello World\nGood bye for now\n' | tee junk2 >&-
      tee: 'standard output': Bad file descriptor
      $ cat junk2
      Hello World
      Good bye for now

    Actually, &- is POSIX Shell compliant.

06. Array variables:

    In bash, all variables are array variables.

       $ foo=bar
       $ echo ${foo[0]}
       bar

       $ gang=(fred daphney thelma)
       $ gang+=(shaggie scooby)
       $ echo ${gang[2]} ${gang[3]}
       thelma shaggie
       $ echo $gang
       fred

    Same as

       $ echo ${gang[0]}
       fred

    Can take contiguous slices of arrays:

       $ echo ${gang[@]:1:3}
       daphney thelma shaggie

       $ echo ${gang[@]:2:2}
       thelma shaggie

    How many are there in the gang?

       $ echo ${#gang[@]}
       5

    Add another character:

       $ gang+=("scrappy    doo")

    When quoted:

       $ for jj in "${gang[@]}"
       > do
       >    echo $jj
       > done
       fred
       daphney
       thelma
       shaggie
       scooby
       scrappy doo

       $ for jj in "${gang[*]}"
       > do
       >   echo $jj
       > done
       fred daphney thelma shaggie scooby scrappy doo

    Instead of shell variable redirection, you get the indices:

       $ echo ${!gang[@]}
       0 1 2 3 4 5

07. Speaking of redirection,

       $ foo=bar
       $ bar=baz
       $ echo ${foo}
       bar
       $ echo ${!foo}
       baz

08. Default values for shell variables:

    Use := within the {} to specify a default value for a
    shell variable, if it is unset or the empty string.

       $ PIE="Apple Pie"
       $ FavoritePie=${PIE:="Cherry Pie"}
       $ FavoriteCake=${CAKE:="Chocolotte Cake"}
       $ echo $FavoritePie
       Apple Pie
       $ echo $FavoriteCake
       Chocolotte Cake

09. Comments begin with a # and can occur anywhere on a line:

       # This is a comment
       Foo="foo"  # This is a comment too.
       Bar="bar"
       # Silly to type comments at the shell prompt, but comments
       # help the reader of a shell script know what is going on.
       echo ${Foo}${Bar}  # This will print "foobar"
                          # without the quotes.
                          # It will work without the brackets,
                          # but I think they make the command
                          # more readable.

10. Shell variables verses environment variables.

    To define a shell variable, use an = with no unquoted spaces.
    These are only known to the current shell.  Other programs
    (but not sub-shells) know nothing about them, you need to
    "export them to the environment."

      $ answer=42
      $ bash          # Completely different instance of bash
      $ echo "The answer is ${answer}."
      The answer is .
      $ exit             # We are back in the original shell.
      $ export answer    # Answer is now known to the environment.
      $ bash           # Brand new instance again.
      $ echo "The answer is ${answer}."
      The answer is 42.
      $ exit       # Also <ctrl-d> will a;so exit you.
      $ answer=53  # Don't have to "re-export" to the environment.
      $ bash
      $ echo "The answer is ${answer}."
      The answer is 53.
      $ answer=0
      $ echo "The answer is ${answer}."
      The answer is 0.
      $ exit
      $ echo "The answer is ${answer}."   # value unchanged
      The answer is 53.

    Note: Unlike the old Solaris Bourne Shell, not to be confused
          with POSIX/Standard Shell, you don't need to re-export
          shell variables every time you change them for their
          new values to be picked up by the environment.

    Note: C Shell (csh) contains two separate namespaces for
          shell and environment variables, which can be very
          confusing for someone with Bash or POSIX/Standard
          Shell experience.

    Bash subshells are not separate instances of bash:

       # Export one shell variable but not the other
       $ export cap=kirk
       $ snd=spock

       $ echo $cap and $snd
       kirk and spock

       # Shell substitution happens in subshell.
       $ (cap=picard; snd=riker; echo $cap and $snd)
       picard and riker

       # Even if unexported, when not defined in
       # the subshell, shell variables will inherit
       # their values from the ones in the parent shell.
       $ (cap=picard; echo $cap and $snd)
       picard and spock

       # This doesn't hold for child processes.
       $ bash -c 'echo $cap and $snd'
       kirk and

       # You can force substitution to happen in the parent shell
       $ eval "(cap=picard; snd=riker; echo $cap and $snd)"
       kirk and spock

       # Bad idea to abuse this feature and start
       # treating Bash like a macro language.
       $ cap2=cap; snd2=snd
       $ dollar='$'
       $ eval "(cap=picard; snd=riker
           echo $cap and $snd
           echo ${dollar}$cap2 and ${dollar}$snd2)"
       kirk and spock
       picard and riker

11. Big and little nibbles:

    Let

      $ aString="Hello big wide world"

    Little nibbles are conservative, they delete the
    smallest possible pattern, # from front, % from rear:

      $ echo ${aString#* }
      big wide world
      $ echo ${aString% *}
      Hello big wide

    Big nibbles are greedy, deleting largest possible pattern.

      $ echo ${aString##* }
      world
      $ echo ${aString%% *}
      Hello

12. Prefer using [[ ... ]] over [ ... ].

    In standard Bourn shell `[' was an actual program called test.
    They are located here: /usr/bin/[
                           /use/bin/test

    On different Unixes, I have seen them sym-linked, hard-linked,
    and separate commands.  I have seen bizzarre bugs in shell
    scripts when people have used test as a shell variable name.

    Anycase, when performing tests, always use [[ ... ]].  Double
    brackets are reserve words in Bash and are much more tolerant
    to empty string evaluations.

    Example:

      $ unset Fruit
      $ if [[ $Fruit == "" ]]
      > then
      >    echo "No Fruit"
      > else
      >    echo Got a $Fruit
      > fi
      No Fruit

   The above will give you a syntax error if you use
   single [ and ].

   Aside: In older shell scripts (and even new Bash scripts!)
          you frequently see constructs like

            $ if [ FOO$Fruit == FOO ]

          for the first line of the test above. This is to get
          around this old wart from the Bourn shell.  This is
          why the [ ... ] shell built-in has the semantics of
          an external command.

   Unfortunately, utilities like make and X-Windows start-up
   scripts use POSIX shell, you still need to be able to deal
   with [ ... ].

   Unlike  [ ... ], [[ ... ]] turns off "file globbing" and
   "field splitting."

13. [[ ... ]] is a "command" on its own and not part of
    the `if' command syntax.

      $ if ls foo >&- 2>&-
      > then
      >     echo "File foo is there."
      > elif ls bar >/dev/null 2>&1
      > then
      >     echo "File bar, but not foo, is there"
      > else
      >     echo "Neither file, foo nor bar, is there."
      > fi
      Neither file, foo nor bar, is there.

      $ if [[ -e foo ]]
      > then
      > echo "File foo is there."
      > elif [[ -e bar ]]
      > then
      >   echo "File bar, but not foo, is there"
      > else
      >   echo "Neither file, foo nor bar, is there."
      > fi
      Neither file, foo nor bar, is there.

14. Use (( ... )) instead of [[ ... ]] for arithmetic and numeric
    testing in Bash.

    Do this:

       ((jj = 40)); while ((jj <= 42))
       do
         echo $jj
         ((jj++))
       done

    Instead of this (still ideomatic Bash):

       jj=39; while [[ $jj -lt 42 ]]
       do
           echo $jj
           let jj=$jj+1
       done

    And absolutely never this (Bourne shell):

      jj=39; while [ $jj -lt 42 ]
      do
          echo $jj
          jj=`expr $jj + 1`
      done

15. Use $(...) instead of back tics `...`.

    $(...) is used to embed the output of a bash command or
    pipeline into a bash script as if you typed it.  It is
    also part of the POSIX standard shell!

    Example:

      for File in $(ls src/main/scala/grockScala/datastructures/*.scala)
      do
        baseName=${File##*/}
        rootName=${File%.scala}
        rm target/scala-2.11/classes/grockScala/datastructures/$rootName.class
      done

    OK, the back tics save you from typing one extra character,
    but they are hard to see and THEY DON'T NEST.

      $ ls -l $(ls $(ls *.pdf))
      -rwxrwxrwx. 1 geoff geoff 2057650 Jan 31 12:13 TLCL.pdf

    You can also embed $(...) in double quoted strings:

      $ helloString="Hello, $(whoami), you use $(uname)."
      $ echo $helloString
      Hello, geoff, you use Linux.

    Here is a nontrivial example:

      $ otherUsers=$(ps -ef | egrep -v "($(whoami)|root|USER)" | sed 's/ .*//' | sort | uniq)
      $ echo $otherUsers
      dbus polkitd postfix rtkit systemd+ UID

16. Comparisons via [[ ... ]] and the non-stictness of && and ||.

    Strings and numerics use different sets of operators:

      $ foo42=42; bar42=fortytwo
      $ [[ $foo42 -lt '50' ]] && echo "true as numbers"
      true as numbers

      $ [[ $foo42 < '50' ]] && echo "true as strings"
      true as strings

      $ [[ forty < $bar42 ]] && echo "true as strings"
      true as strings

      $ [[ twenty < forty ]] || echo "false as strings"
      false as strings

    Aside: The && and || operators "short circuit" that
           is they are non-strict in their second argument.

19. Some properties of square bracket expressions:

      [ ... ] are tests
      [[ ... ]] evaluate conditional expressions

    Empty tests and an empty test false:

      $ [ ]
      $ echo $?
      1

      $ test
      $ echo $?
      1

      $ [ '' ]; echo $?
      1

      $ [ $(false) ] && echo '$(false) evaluates to the empty string'
      $

    A non-empty (non-special) single string tests true:

      $ [ some_string ]; echo $?
      0

      $ [ 1 ]; echo $?
      0

      $ [ 0 ]; echo $?
      0

      $ [ ' ' ]; echo $?
      0

      $ [ false ] && echo "false is just a string, not the built-in"
      false is just a string, not the built-in

    Multiple (non-special) strings is an error:

      $ [ some strings ]
      bash: [: some: unary operator expected

      $ [ more than one ]
      bash: [: than: binary operator expected

      $ [ 3 -lt  5 ] && echo yes
      yes

      $ [ 3 -gt  5 ] || echo no
      no

    Empty conditional expressions are syntax errors:

      $ [[ ]]
      bash: syntax error near `]]'

    An empty string evaluates false:

      $ [[ '' ]]; echo $?
      1

      $ [[ $(true) ]] || echo '$(true) evaluates to an empty string'
      $(true) evaluates to an empty string
      $ echo '>>>'$(true)'<<<'
      >>><<<

    A single string evaluates true

      $ [[ foobar ]]; echo $?
      0

    Note: I would never write a script that depends on a lot of
          the above behaviors.  But it is helpful to understand
          the above when debugging other people's "POSIX compliant"
          shell scripts.

18. Like & or |&, && and || cannot be used within single
    square brackets.  For "and" and "or" comparisons:

      # Traditional way
      $ [ 4 -eq 2 -a 5 -gt 3 ] || echo False
      False
      $ [ 4 -eq 2 -o 5 -gt 3 ] && echo True
      True

      # Preferred way
      $ [ 4 -eq 2 ] && [ 5 -gt 3 ] || echo False
      False
      $ [ 4 -eq 2 ] || [ 5 -gt 3 ] && echo True
      True

19. Order of operations for logical operators can be very
    confusing.

    Both && and || short circuit and are left to right
    associative, but their precedence depends on the context.

    Outside of double square brackets [[ ... ]], && and ||
    behave like functions (operators) which return (integer)
    values 0 for true and 1 for false.  Like the true and false
    shell built-in functions, they have no "side effects",
    that is they don't print anything to the terminal.

    Outside of square brackets, && and || have equal precedence.

    Inside double square brackets they have their usual
    mathematical precedence, && is higher than ||.

    Example:

      $ [[ x == x ]] || [[ x == y ]] && [[ x == y ]]
      $ echo $?
      1

      $ [[ x == x || x == y && x == y ]]
      $ echo $?
      0

    Very confusing, if you use one to establish "how Bash works,"
    then when the other "fails" you don't understand why!

20. You can match on regular expressions with [[ ]]:

      $ fName=myMatlabProg.m
      $ if [[ $fName =~ .*\.m ]]
      then
        echo "MATLAB file"
      else
        echo "Something else"
      fi
      MATLAB file

    You can also put the regular expression in a shell variable:

      $ fName=myMatlabProg.m
      $ regEx='.*\.m'
      $ if [[ $fName =~ $regEx ]]
      > then
      >   echo "MATLAB file"
      > else
      >   echo "Something else"
      > fi
      MATLAB file

21. Looping constructs:

    Loop a fixed number of times,

      $ for ii in {1..10..3}
      > do
      >    echo $ii
      > done
      1
      4
      7
      10

    More general construct modelled after C programming,

      $ n=4
      $ for ((ii = 0; ii < n; ii++))
      > do
      >   echo $ii
      >done
      0
      1
      2
      3

    More Pythonic construct,

      $ jj=42; jj[1]=5; jj[2]=11
      > for ii in ${jj[*]}
      > do
      >   echo $ii
      > done
      42
      5
      11

    Using a while loop,

      $ Line=""; while [[ ! $Line =~ [y|Y] ]]
      > do
      >   echo -n "Quit? [y|Y]: "
      >   read Line
      > done
      Quit? [y|Y]: g
      Quit? [y|Y]: n
      Quit? [y|Y]: y
      $

21. Shell functions:

    Shell functions are bash subroutines that execute in the
    context of the current shell.  These "functions" don't really
    return values apart from small integer error codes.

    Two examples, first POSIX style, second Korn Shell style

      # PDF Reader
      ev() {
        ( /usr/bin/evince "$@" &>/dev/null & )
      }

      ## pop up multiple directories (takes an optional parameter)
      function ud {
          local upDir=../
          if [[ $1 =~ ^[1-9][0-9]*$ ]]
          then
            for ((ii = 1; ii < $1; ii++))
            do
              upDir=../$upDir
            done
          fi
          cd $upDir
      }

    To list the names of all the shell functions defined in your
    current environment,

      $ declare -F
      declare -f dequote
      declare -f ev
      declare -f gc
      declare -f quote
      declare -f quote_readline
      declare -f ud

   To type out the definition to one,

     $ declare -f ev
     ev ()
     {
         ( /usr/bin/evince "$@" &> /dev/null & )
     }

  Variables can be declared local to the function body via
  the `local' keyword,

    $ a=a1; b=b1
    $ echo $a $b
    a1 b1

    $ function baz {
    >   echo $a $b
    >   a=a2
    >   local b=b2
    >   echo $a $b
    > }

    $ echo $a $b
    a1 b1
    $ baz
    a1 b1
    a2 b2
    $ echo $a $b
    a2 b1

22. Aliases:

    The alias command allows a string to be substituted as the
    first word of a simple command.  Useful if you want to
    change the default behavior of a command.

      $ unalias ls 2>&-  # Undo any evil done in startup scripts.
      $ alias la='ls -a'   # Show .files.
      $ alias l.='ls -dA .* --color=auto'   # Show just .files, with color.
      $ alias vi=vim   # Overcome years of muscle memory.
      $ alias gvim='gvim -c "colorscheme desert"'

    Alias are intended as typing conveniences and should only be
    used for simple substitutions.  For any thing more complicated
    than say

      $ alias pst="ps axjf | sed -e '/^ PPID.*$/d' -e's/.*:...//'"

    Use a shell function instead.  The Bash man page actually
    says "For almost every purpose, aliases are superseded by
    shell functions."

    Alias substitution was intended only for interactive shell
    sessions.  To enable alias substitution in a shell script,
    include this line in the script:

      shopt -s expand_aliases   # Probably a bad idea

23. Example here document.

      #!/bin/bash

      name=Foofoo

      cat <<DOC1
      hello World
      $name rules!
      DOC1

      cat >&2 <<-DOC2
        death to all who
        oppose the $name!
      DOC2

    Method of using text from the shell script itself as input.
    Good for scripting the mailx command in a shell script.

    The <<- variant ignores initial tabs for a "more nature"
    indentation.

24. Bash output to stdout/stderr

  In shell scripts and functions, I prefer printf over echo
  for sending text to stdout/stderr.  The printf builtin gives
  you more control and is more consistent across different
  shells than echo.  It is modeled after printf from C.

  I still use echo at the command line.  I also use echo
  when debugging shell scripts/functions.  Makes it easier
  to find the debug lines to remove later.

  The first argument to printf is a format string.  Best practice
  is to let the printf builtin do the intepolation and not use
  " ... " interpolation.  Especially true if user input is involved.

    $ printf '%s:%3d%7.4f\n' answers 42 3.14159
    answers: 42 3.1416

    $ echo 'foo\nbar'
    foo\nbar
    $ echo -e 'foo\nbar'
    foo
    bar
    $ echo -en 'foo\nbar'
    foo
    bar$

25. Bash Input from stdin

  Read one line at a time:

    $ echo '11 12 13
            21 22 23
            31 32 33' | while read first second third
        do
            printf 'first as string: %s\n' "$first"
            printf 'second as decimal int: %d\n' "$second"
            printf 'third as floating point number %4.1f\n' "$third"
        done
    first as string: 11
    second as decimal int: 12
    third as floating point number 13.0
    first as string: 21
    second as decimal int: 22
    third as floating point number 23.0
    first as string: 31
    second as decimal int: 32
    third as floating point number 33.0

  Read one line at a time into an array:

    $ echo '11 12 13
            21 22 23 24 25
            31 32' | while read -a elem
        do
            for element in "${elem[@]}"
            do
              printf '%s ' "$element"
            done
            printf '\n'
        done
    11 12 13
    21 22 23 24 25
    31 32

  Read all lines into an array:

    $ echo '11 12 13
            21 22 23
            31 32 33' | {
      readarray -t lines
      echo "${lines[2]}" | { read zeroth rest
         printf 'The zeroth item of the second row is '
         printf '%s.\n' $zeroth
      }
    }
    The zeroth item of the second row is 31.

  Note: mapfile is another name for readarray.  The -t option
        for readarray trims off the trailing newline.

  Note: There are a lot of additional options read and readarray
        can take.  See the SHELL BUILTIN COMMANDS section of the
        bash manpage for details.

  Note: The default hehavior of read is to to use \ as an escape
        character.  Use option -r to prevent this and intepret \
        literally.

          $ printf 'hello \
          world\n' | while read -r a b c
                     do
                        printf 'a = "%s"\nb = "%s"\nc = "%s"\n' "$a" "$b" "$c"
                     done
          a = "hello"
          b = "\"
          c = ""
          a = "world"
          b = ""
          c = ""

          $ printf 'hello \
          world\n' | while read a b c
                     do
                        printf 'a = "%s"\nb = "%s"\nc = "%s"\n' "$a" "$b" "$c"
                     done
          a = "hello"
          b = "world"
          c = ""

  Note: Unlike Ksh, the last command of a pipeline is not interpreted in
        the context of the current shell.  Hence the use of compound
        commands in some of the above examples.

          $ BAR=foo; printf 'bar' | read BAR
          $ echo $BAR
          foo

        To make bash have the ksh behavior, use the lastpipe shopt.

          $ set +m
          $ shopt -s lastpipe
          $ BAR=foo; printf 'bar' | read BAR
          $ echo $BAR
          bar

        I had to turn job control off for the lastpipe shopt to work
        in a terminal.  No need for "set +m" in a script.

26. Editing differences between vi and bash in vi mode:

    You can use

      $ set -o vi

    to switch from the default emacs bash cmdline editing mode.

    Some differences from vi while in "normal mode" are:

      <cntl-k>      delete from cursor to end of line
      <cntl-u>      delete from before cursor beginning of line
      k             previous command in history (at beginning)
      <up-arrow>    previous command in history (at beginning)
      j             next line in history (at beginning)
      <down-arrow>  next line in history (at beginning)
      #             prepend # to current line and put in history

    while in typing mode:

      <up-arrow>    previous command in history (end of line)
      <down-arror>  next line in history (end of line)

    and in either command or typing mode:

      <ctrl-r>    reverse search history,
                    <ret> to execute
                    <esc> to edit
      <ctrl-s>    forward search history,
                    <ret> to execute
                    <esc> to edit

    Note: To use <ctrl-s>, you need to turn off terminal flow
          control.  To do this, use the "stty -ixon" command.
          You will no longer be able to use <ctrl-s> to stop
          output and <ctrl-u> to start it again.  Use "stty ixon"
          to turn flow control back on.

    You can edit the command line with your favorite
    editor via "<Esc>v".  Bash attempts to invoke shell
    variables $VISUAL, $EDITOR, and emacs as the editor,
    in that order.  This id particularly useful when
    editing multi-line commands.

27. Configuring Bash.

    Bash, like any good GNU application, honors the
    ~/.inputrc file.  See the READLINE section of the Bash manpage.

    Here is what I use in mine to customize Bash:

      # Include system inputrc
      $include /etc/inputrc

      # Use vi editing mode instead of default emacs editing mode
      set editing-mode vi

      # Change prompt if in command vs insert mode
      set show-mode-in-prompt on

      $if term=linux
          set vi-ins-mode-string \1\e[?0c\2
          set vi-cmd-mode-string \1\e[?8c\2
      $else
          set vi-ins-mode-string \1\e[6 q\2
          set vi-cmd-mode-string \1\e[2 q\2
      $endif

      # Append a "/" to tab completed symlinks
      set mark-symlinked-directories on

      # Do not cut and paste from websites,
      # but if you do this provides some
      # protection from nefarious strings.
      set enable-bracketed-paste on

      # History search based on what you have typed so far
      $if mode=vi
      set keymap vi-command
      # these are for vi-command mode
      "\e[A": history-search-backward
      "\e[B": history-search-forward
      j: history-search-forward
      k: history-search-backward
      set keymap vi-insert
      # these are for vi-insert mode
      "\e[A": history-search-backward
      "\e[B": history-search-forward
      $endif
